Hyper Parameters,Skin1 Accuracy,Skin1 Sensitivity,Skin1 Specificity,Skin1 Precision,Skin1 Score,Skin1 AUC,Skin2 Accuracy,Skin2 Sensitivity,Skin2 Specificity,Skin2 Precision,Skin2 Score,Skin2 AUC
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = AdamW  scheduler = CosineAnnealingLR  batch_size = 32  epochs = 19  max_stop_count = 10  grad_norm_clip = 1  ,0.5085,0.0104,0.9899,0.5,0.0204,0.5002,0.4839,0.0303,1,1,0.0588,0.5152
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = AdamW  scheduler = fixed  batch_size = 32  epochs = 22  max_stop_count = 10  grad_norm_clip = 1  ,0.6024,0.7951,0.4161,0.5682,0.6628,0.6056,0.5323,0.6364,0.4138,0.5526,0.5915,0.5251
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = AdamW  scheduler = StepLR  batch_size = 32  epochs = 22  max_stop_count = 10  grad_norm_clip = 1  ,0.5648,0.4722,0.6544,0.569,0.5161,0.5633,0.5484,0.3333,0.7931,0.6471,0.44,0.5632
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = Adam  scheduler = fixed  batch_size = 32  epochs = 23  max_stop_count = 10  grad_norm_clip = 1  ,0.587,0.5729,0.6007,0.581,0.5769,0.5868,0.5645,0.5758,0.5517,0.5938,0.5846,0.5637
learning_rate = 0.001  weight_decay = 0.0001  scheduler = CosineAnnealingLR  batch_size = 32  epochs = 11  max_stop_count = 5  grad_norm_clip = 1  ,0.8123,0.7708,0.8523,0.8346,0.8014,0.8116,0.8226,0.7879,0.8621,0.8667,0.8254,0.825
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = SGD  scheduler = fixed  batch_size = 32  epochs = 15  max_stop_count = 10  grad_norm_clip = 1  ,0.7986,0.8229,0.7752,0.7796,0.8007,0.799,0.7581,0.8485,0.6552,0.7368,0.7887,0.7518
learning_rate = 0.001  weight_decay = 0.0001  optimizer_type = SGD  scheduler = StepLR  batch_size = 32  epochs = 16  max_stop_count = 10  grad_norm_clip = 1  ,0.8157,0.7986,0.8322,0.8214,0.8099,0.8154,0.8065,0.7879,0.8276,0.8387,0.8125,0.8077
