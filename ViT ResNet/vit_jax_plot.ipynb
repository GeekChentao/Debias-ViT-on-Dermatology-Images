{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"imagenet21k_ViT-B_32\"  # @param [\"ViT-B_32\", \"Mixer-B_16\"]\n",
    "\n",
    "import os\n",
    "\n",
    "assert os.path.exists(f\"{model_name}.npz\")\n",
    "\n",
    "model_name = \"ViT-B_32\"\n",
    "\n",
    "\n",
    "from absl import logging\n",
    "import flax\n",
    "import jax\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "# Shows the number of available devices.\n",
    "# In a CPU/GPU runtime this will be a single device.\n",
    "# In a TPU runtime this will be 8 cores.\n",
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"./vision_transformer\" not in sys.path:\n",
    "    sys.path.append(\"./vision_transformer\")\n",
    "\n",
    "\n",
    "# Helper functions for images.\n",
    "\n",
    "labelnames = dict(\n",
    "    skin=(\"benign\", \"malignant\"),\n",
    ")\n",
    "\n",
    "\n",
    "def make_label_getter(dataset):\n",
    "    \"\"\"Returns a function converting label indices to names.\"\"\"\n",
    "\n",
    "    def getter(label):\n",
    "        if dataset in labelnames:\n",
    "            return labelnames[dataset][label]\n",
    "        return f\"label={label}\"\n",
    "\n",
    "    return getter\n",
    "\n",
    "\n",
    "def show_img(img, ax=None, title=None):\n",
    "    \"\"\"Shows a single image.\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # ax.imshow(img[...])\n",
    "    print(img.shape)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def show_img_grid(imgs, titles):\n",
    "    \"\"\"Shows a grid of images.\"\"\"\n",
    "    n = int(np.ceil(len(imgs) ** 0.5))\n",
    "    _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "    for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "        img = (img + 1) / 2  # Denormalize\n",
    "        show_img(img, axs[i // n][i % n], title)\n",
    "\n",
    "\n",
    "\"\"\"### Load dataset\"\"\"\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, label, skin, img_size):\n",
    "    # Read the image file\n",
    "    base_dir = \"Fitzpatric_subset\"\n",
    "    image_path = tf.strings.join([base_dir, image_path], separator=\"/\")\n",
    "    image_path = tf.strings.join([image_path, \".jpg\"])\n",
    "\n",
    "    # Read and decode the image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Resize the image\n",
    "    image = tf.image.resize(image, (img_size, img_size))\n",
    "\n",
    "    # Normalize the image to [-1, 1] Double check range\n",
    "    image = (image / 127.5) - 1.0\n",
    "\n",
    "    return image, label, int(skin)\n",
    "\n",
    "\n",
    "def load_dataset_from_csv(csv_file, img_size, batch_size, mode):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    num_classes = df[\"lesion\"].nunique()\n",
    "    df[\"lesion\"] = df[\"lesion\"].apply(lambda x: tf.one_hot(x, num_classes))\n",
    "\n",
    "    # Create a dataset of (image_path, label) pairs\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (df[\"image_path\"].values, df[\"lesion\"].tolist(), df[\"skin_color\"].tolist())\n",
    "    )\n",
    "\n",
    "    # Apply the preprocessing function\n",
    "    dataset = dataset.map(\n",
    "        lambda img_path, label, skin: preprocess_image(img_path, label, skin, img_size),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Convert each element to a dictionary\n",
    "    dataset = dataset.map(\n",
    "        lambda image, label, skin: {\n",
    "            \"image\": image,\n",
    "            \"label\": label,\n",
    "            \"skin\": skin,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Add an extra dimension to the entire batch to match model input shape\n",
    "    dataset = dataset.map(\n",
    "        lambda batch: {\n",
    "            \"image\": tf.expand_dims(\n",
    "                batch[\"image\"], axis=0\n",
    "            ),  # Add batch dimension to images\n",
    "            \"label\": tf.expand_dims(\n",
    "                batch[\"label\"], axis=0\n",
    "            ),  # Add batch dimension to labels\n",
    "            \"skin\": tf.expand_dims(\n",
    "                batch[\"skin\"], axis=0\n",
    "            ),  # Add batch dimension to labels\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Shuffle and repeat for training\n",
    "    if mode == \"train\":\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # Prefetch for performance\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_jax import checkpoint\n",
    "from vit_jax import input_pipeline\n",
    "from vit_jax import utils\n",
    "from vit_jax import models\n",
    "from vit_jax import train\n",
    "from vit_jax.configs import common as common_config\n",
    "from vit_jax.configs import models as models_config\n",
    "\n",
    "dataset = \"skin\"\n",
    "batch_size = 512  # 16 32\n",
    "config = common_config.with_dataset(common_config.get_config(), dataset)\n",
    "# config.batch = batch_size\n",
    "# config.pp.crop = 224  ## 300 resize check\n",
    "\n",
    "\n",
    "# Load training and test datasets\n",
    "train_data = load_dataset_from_csv(\n",
    "    \"train_data.csv\", img_size=224, batch_size=batch_size, mode=\"train\"\n",
    ")\n",
    "test_data = load_dataset_from_csv(\n",
    "    \"test_data.csv\", img_size=224, batch_size=batch_size, mode=\"test\"\n",
    ")\n",
    "\n",
    "# For details about setting up datasets, see input_pipeline.py on the right.\n",
    "ds_train = input_pipeline.get_data_from_tfds(config=config, mode=\"train\")\n",
    "ds_test = input_pipeline.get_data_from_tfds(config=config, mode=\"test\")\n",
    "ds_train = train_data\n",
    "ds_test = test_data\n",
    "# num_classes = input_pipeline.get_dataset_info(dataset, \"train\")[\"num_classes\"]\n",
    "num_classes = 2\n",
    "# print(f\"num classes = {num_classes}\")\n",
    "# for images, labels in train_data.take(1):  # Take one batch for inspection\n",
    "#     print(\"Images shape:\", images.shape)\n",
    "#     print(\"Labels shape:\", labels.shape)\n",
    "# print(\"Images batch:\", images)\n",
    "# print(\"Labels batch:\", labels)\n",
    "# del config  # Only needed to instantiate datasets.\n",
    "\n",
    "# Fetch a batch of test images for illustration purposes.\n",
    "batch = next(iter(ds_test.as_numpy_iterator()))\n",
    "# Note the shape : [num_local_devices, local_batch_size, h, w, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some images with their labels.\n",
    "images, labels = batch[\"image\"][0][:9], batch[\"label\"][0][:9]\n",
    "titles = map(make_label_getter(dataset), labels.argmax(axis=1))\n",
    "show_img_grid(images, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but with train images.\n",
    "# Note how images are cropped/scaled differently.\n",
    "# Check out input_pipeline.get_data() in the editor at your right to see how the\n",
    "# images are preprocessed differently.\n",
    "images, labels = batch[\"image\"][0][:9], batch[\"label\"][0][:9]\n",
    "titles = map(make_label_getter(dataset), labels.argmax(axis=1))\n",
    "show_img_grid(images, titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
