{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"skincap.xlsx\")\n",
    "\n",
    "file_paths = df[\"ori_file_path\"].tolist()\n",
    "descriptions = df[\"caption_en\"].tolist()\n",
    "# dir_path = \"Fitzpatric_subset\"\n",
    "dir_path = \"ddidiversedermatologyimages\"\n",
    "img_descs = []\n",
    "\n",
    "\n",
    "# Filter existing image paths\n",
    "for file_path, description in zip(file_paths, descriptions):\n",
    "    path = os.path.join(dir_path, file_path)\n",
    "    if os.path.exists(path):\n",
    "        img_descs.append((path, description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "learning_size = 32\n",
    "np.random.seed(20)\n",
    "indices = np.random.choice(len(img_descs), learning_size)\n",
    "samples = np.array(img_descs)[indices]\n",
    "\n",
    "\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 500\n",
      "A white nodule is visible on the inside of the mouth.\n",
      "\n",
      "image 501\n",
      "The photo shows a reddish, nodular skin lesion with visible blood vessels and some scaling on the surface.\n",
      "\n",
      "image 502\n",
      "Multiple red papules can be seen on the skin.\n",
      "\n",
      "image 503\n",
      "The photo shows a red nodule with visible skin lines on its surface.\n",
      "\n",
      "image 504\n",
      "The image shows a dark black/blue mole with an oval shape and symmetric border.\n",
      "\n",
      "image 505\n",
      "Red maculopapular rash on the back and arms.\n",
      "\n",
      "image 506\n",
      "A large section of skin is covered in small, white papules.\n",
      "\n",
      "image 507\n",
      "The photo shows a section of skin with hair follicles and several papules of varying sizes.\n",
      "\n",
      "image 508\n",
      "A well-defined patch of red skin with a rough, scaly texture.\n",
      "\n",
      "image 509\n",
      "The photo shows multiple black spots and nodular bumps clustered closely together.\n",
      "\n",
      "image 510\n",
      "A pink soft tissue with a bulbous tip\n",
      "\n",
      "image 511\n",
      "The image shows a nodule on the lip.\n",
      "\n",
      "image 512\n",
      "There is a red, raised nodule on the skin.\n",
      "\n",
      "image 513\n",
      "Dark papule on the head.\n",
      "\n",
      "image 514\n",
      "Red skin with scaling.\n",
      "\n",
      "image 515\n",
      "Skin lesion on the nose, red with irregular edges and capillaries\n",
      "\n",
      "image 516\n",
      "Red, circular lesion.\n",
      "\n",
      "image 517\n",
      "Red papules covering the body\n",
      "\n",
      "image 518\n",
      "no description\n",
      "\n",
      "image 519\n",
      "There are numerous red papules on both arms.\n",
      "\n",
      "image 520\n",
      "The photo shows a skin lesion on the forehead.\n",
      "\n",
      "image 521\n",
      "The photo shows a large mass on the lower lip.\n",
      "\n",
      "image 522\n",
      "Skin ulcer with clear borders, reddish-white center and no pus.\n",
      "\n",
      "image 523\n",
      "A close up of a person's eye with various white bumps and spots around the eyelid and surrounding area.\n",
      "\n",
      "image 524\n",
      "The image shows a collection of slightly raised skin lesion with a slightly darker border.\n",
      "\n",
      "image 525\n",
      "Multiple papules with normal skin color are visible around the eye.\n",
      "\n",
      "image 526\n",
      "A bright red skin leision is visible on the ear.\n",
      "\n",
      "image 527\n",
      "The picture shows a raised, skin-colored nodule with a smooth surface.\n",
      "\n",
      "image 528\n",
      "The image shows several areas on the palm of the hand which appear thick with yellowed skin.\n",
      "\n",
      "image 529\n",
      "A light colored, circular skin rash with darker dots in the middle.\n",
      "\n",
      "image 530\n",
      "The photo shows red patches with inflammation.\n",
      "\n",
      "image 531\n",
      "Multiple bumps on arm.\n",
      "\n",
      "image 532\n",
      "The image shows a red and orange nodule protruding from the skin.\n",
      "\n",
      "image 533\n",
      "no description\n",
      "\n",
      "image 534\n",
      "A row of bumps, some fluid-filled, some scabbed over, along the abdomen.\n",
      "\n",
      "image 535\n",
      "Several raised irregular, discolored patches on face, forehead, and nose.\n",
      "\n",
      "image 536\n",
      "Raised round spot on the body.\n",
      "\n",
      "image 537\n",
      "The photo shows numerous very small red spots spread across the torso.\n",
      "\n",
      "image 538\n",
      "The photo shows a red sore on the scalp with some yellow crusting.\n",
      "\n",
      "image 539\n",
      "The photo shows numerous small red spots with some skin irritation.\n",
      "\n",
      "image 540\n",
      "The photo shows multiple papules with some inflammation on the chest.\n",
      "\n",
      "image 541\n",
      "Small cluster of red papules\n",
      "\n",
      "image 542\n",
      "The skin on the forehead is discolored and darkened.\n",
      "\n",
      "image 543\n",
      "Dark irregular skin growth surrounded by redness.\n",
      "\n",
      "image 544\n",
      "The skin around one fingernail is red, swollen, and damaged.\n",
      "\n",
      "image 545\n",
      "The photo shows multiple irritated, round lesions of varying sizes on the lower leg.\n",
      "\n",
      "image 546\n",
      "The photo shows a bright red and elongated nodule protruding from the skin.\n",
      "\n",
      "image 547\n",
      "The photo shows a nodule with multiple colors on hand.\n",
      "\n",
      "image 548\n",
      "The image shows areas of redness with some skin irritation.\n",
      "\n",
      "image 549\n",
      "The photo shows a raised red nodule.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCpwS557k9laRC2Kdh_ylEQwFcn5TbSO_E\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "def generate_description(samples, image_paths, id):\n",
    "    \"\"\"Accept a batch size of images and write description for each image\"\"\"\n",
    "    inputs = [\n",
    "        item\n",
    "        for sublist in [\n",
    "            [PIL.Image.open(path), description] for path, description in samples\n",
    "        ]\n",
    "        for item in sublist\n",
    "    ]\n",
    "    cmd = (\n",
    "        \"Study 32 image and diagnose pair examples above and generate leision description for this image,\"\n",
    "        'only genereate the description in a paragraph, don\\'t say ANYTHING inrevalent not even saying \"Ok\",'\n",
    "        'if you cannot genereate a descriotion, just say \"no description\"'\n",
    "        \"generate in this format image \"\n",
    "    )\n",
    "    for path in image_paths:\n",
    "        input = cmd + str(id) + \"{new line} description\"\n",
    "        inputs += [input, PIL.Image.open(path)]\n",
    "        id += 1\n",
    "    response = model.generate_content(inputs)\n",
    "    print(response.text)\n",
    "\n",
    "\n",
    "data_dir = \"Fitzpatric_subset\"\n",
    "train_data_file = \"train_data.csv\"\n",
    "validation_data_file = \"validation_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "test_data = pd.read_csv(test_data_file)\n",
    "# print(train_data.head())\n",
    "image_paths = test_data[\"image_path\"].tolist()\n",
    "batch_size = 50\n",
    "for i in range(500, len(image_paths), batch_size):\n",
    "    paths = image_paths[i : i + batch_size]\n",
    "    paths = [os.path.join(data_dir, path) + \".jpg\" for path in paths]\n",
    "    generate_description(samples, paths, i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08a183312614facc181ff92c032dc8b0\n"
     ]
    }
   ],
   "source": [
    "img = train_image_paths[652]\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class 'method'>\nValue: <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x00000253A38D4AA0>>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m diagnoses \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, diagnose \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(test_data, response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\generative_models.py:305\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 305\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole:\n\u001b[0;32m    314\u001b[0m     request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\generative_models.py:154\u001b[0m, in \u001b[0;36mGenerativeModel._prepare_request\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     tool_config \u001b[38;5;241m=\u001b[39m content_types\u001b[38;5;241m.\u001b[39mto_tool_config(tool_config)\n\u001b[1;32m--> 154\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m generation_types\u001b[38;5;241m.\u001b[39mto_generation_config_dict(generation_config)\n\u001b[0;32m    157\u001b[0m merged_gc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generation_config\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:333\u001b[0m, in \u001b[0;36mto_contents\u001b[1;34m(contents)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;66;03m# If you get a TypeError here it's probably because that was a list\u001b[39;00m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;66;03m# of parts, not a list of contents, so fall back to `to_content`.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m contents \u001b[38;5;241m=\u001b[39m [\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:299\u001b[0m, in \u001b[0;36mto_content\u001b[1;34m(content)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[to_part(part) \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m content])\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# Maybe this is a Part?\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[\u001b[43mto_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m])\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:264\u001b[0m, in \u001b[0;36mto_part\u001b[1;34m(part)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mPart(function_response\u001b[38;5;241m=\u001b[39mpart)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# Maybe it can be turned into a blob?\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mPart(inline_data\u001b[38;5;241m=\u001b[39m\u001b[43mto_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:210\u001b[0m, in \u001b[0;36mto_blob\u001b[1;34m(blob)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blob, Mapping):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not recognize the intended type of the `dict`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA content should have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m     )\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create `Blob`, expected `Blob`, `dict` or an `Image` type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(`PIL.Image.Image` or `IPython.display.Image`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(blob)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class 'method'>\nValue: <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x00000253A38D4AA0>>"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(input)\n",
    "\n",
    "diagnoses = {}\n",
    "for data, diagnose in zip(test_data, response.text.split(\"\\n\")):\n",
    "    diagnoses[data[0]] = diagnose\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyCMwGga7tVM2uq-7AKevOrBne6InYnL6As\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "import os\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"AIzaSyCMwGga7tVM2uq-7AKevOrBne6InYnL6As\")\n",
    "\n",
    "# Load batch of 32 images and their captions\n",
    "image_folder = \"./Fitzpatric_subset/\"\n",
    "captions = [\n",
    "    \"Caption for image 1\",\n",
    "    \"Caption for image 2\",\n",
    "    ...,\n",
    "    \"Caption for image 32\",\n",
    "]  # Replace with actual captions\n",
    "\n",
    "# Get list of image paths\n",
    "image_files = sorted(\n",
    "    [\n",
    "        os.path.join(image_folder, f)\n",
    "        for f in os.listdir(image_folder)\n",
    "        if f.endswith((\".jpg\", \".png\"))\n",
    "    ]\n",
    ")[:32]\n",
    "\n",
    "# Load images\n",
    "images = [PIL.Image.open(img_path) for img_path in image_files]\n",
    "\n",
    "# Prepare input with examples\n",
    "examples = []\n",
    "for img, caption in zip(images, captions):\n",
    "    examples.append([img, caption])\n",
    "\n",
    "# Define a new image for testing (optional)\n",
    "new_image_path = \"./test_image.jpg\"  # Replace with a test image\n",
    "new_image = PIL.Image.open(new_image_path)\n",
    "\n",
    "# Prompt model with few-shot learning\n",
    "model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "response = model.generate_content(\n",
    "    examples + [[new_image, \"Generate a caption for this image.\"]]\n",
    ")\n",
    "\n",
    "# Output generated caption\n",
    "print(\"Generated Caption:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Configure API Key\n",
    "genai.configure(api_key=\"AIzaSyCMwGga7tVM2uq-7AKevOrBne6InYnL6As\")\n",
    "\n",
    "# Define paths\n",
    "image_folder = \"./Fitzpatric_subset/\"\n",
    "output_file = \"generated_captions.json\"\n",
    "\n",
    "# Load 32 reference images with captions\n",
    "reference_captions = [\n",
    "    \"Caption for image 1\",\n",
    "    \"Caption for image 2\",\n",
    "    ...,\n",
    "    \"Caption for image 32\",\n",
    "]  # Replace with actual captions\n",
    "\n",
    "image_files = sorted(\n",
    "    [\n",
    "        os.path.join(image_folder, f)\n",
    "        for f in os.listdir(image_folder)\n",
    "        if f.endswith((\".jpg\", \".png\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load first 32 images as reference examples\n",
    "reference_images = [PIL.Image.open(img_path) for img_path in image_files[:32]]\n",
    "\n",
    "# Prepare examples for few-shot learning\n",
    "examples = [\n",
    "    [img, caption] for img, caption in zip(reference_images, reference_captions)\n",
    "]\n",
    "\n",
    "# List to store results\n",
    "generated_captions = {}\n",
    "\n",
    "# Process remaining images in batches\n",
    "batch_size = 32\n",
    "new_images = image_files[32:]  # Remaining images (1000+)\n",
    "\n",
    "for i in range(0, len(new_images), batch_size):\n",
    "    batch_paths = new_images[i : i + batch_size]\n",
    "    batch_images = [PIL.Image.open(img) for img in batch_paths]\n",
    "\n",
    "    # Prepare request\n",
    "    inputs = examples + [\n",
    "        [img, \"Generate a caption for this image.\"] for img in batch_images\n",
    "    ]\n",
    "\n",
    "    # Generate captions\n",
    "    model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "    response = model.generate_content(inputs)\n",
    "\n",
    "    # Store results\n",
    "    for img_path, caption in zip(batch_paths, response.text.split(\"\\n\")):\n",
    "        generated_captions[img_path] = caption.strip()\n",
    "\n",
    "    print(f\"Processed batch {i // batch_size + 1}/{len(new_images) // batch_size + 1}\")\n",
    "\n",
    "# Save generated captions\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(generated_captions, f, indent=4)\n",
    "\n",
    "print(f\"Saved {len(generated_captions)} generated captions to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [4, 5, 6]\n",
    "l3 = l1 + l2\n",
    "print(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for data in range(5) for item in [3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
